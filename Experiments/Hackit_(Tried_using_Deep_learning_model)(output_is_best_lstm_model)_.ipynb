{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x1JDpWsdCQDW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount with google drive\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3aTvQPRF8lz",
        "outputId": "34256b32-9fca-474f-943b-ac6d6f295975"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/final_data.csv\")"
      ],
      "metadata": {
        "id": "sJVYf-lxC36r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UinBobqwC-ar",
        "outputId": "cb8903ef-31b3-40da-f499-767095d65735"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text    emotion  \\\n",
              "0                 I am getting a lot of weird replies...    Neutral   \n",
              "1                                     Why is it illegal?    Neutral   \n",
              "2      [NAME] just think of how overworked her liver ...  Happiness   \n",
              "3      But doing those things makes me feel so.... icky.    Sadness   \n",
              "4                                           Shame on you      Anger   \n",
              "...                                                  ...        ...   \n",
              "57116  Ha, that would be a novel experience. He'd bet...     Desire   \n",
              "57117        Very sad. People like this are ruining Aus.    Sadness   \n",
              "57118  It was worth mentioning anyways, the Packers a...    Neutral   \n",
              "57119  They want to make gun ownership so expensive a...      Anger   \n",
              "57120  Idk if I want [NAME] back but I agree with [NA...     Desire   \n",
              "\n",
              "                                            cleaned_text  \\\n",
              "0                              getting lot weird replies   \n",
              "1                                                illegal   \n",
              "2               name think overworked liver kidneys must   \n",
              "3                                 things makes feel icky   \n",
              "4                                                  shame   \n",
              "...                                                  ...   \n",
              "57116          ha would novel experience better let deal   \n",
              "57117                        sad people like ruining aus   \n",
              "57118  worth mentioning anyways packers special kind ...   \n",
              "57119  want make gun ownership expensive onerous peop...   \n",
              "57120  idk want name back agree name keeps playing le...   \n",
              "\n",
              "                                               embedding  emotion_Anger  \\\n",
              "0      [[ 3.57603505e-02  1.88769430e-01 -5.63014112e...            0.0   \n",
              "1      [[-3.13512266e-01  5.34555972e-01 -5.06467640e...            0.0   \n",
              "2      [[-9.83442590e-02  3.89946789e-01 -4.01094072e...            0.0   \n",
              "3      [[ 4.80609946e-02  3.33314270e-01  1.51030645e...            0.0   \n",
              "4      [[-8.55700299e-02  2.50925511e-01 -1.43386796e...            1.0   \n",
              "...                                                  ...            ...   \n",
              "57116  [[-2.79613025e-02  1.31248564e-01 -1.78521685e...            0.0   \n",
              "57117  [[ 1.09247044e-01  3.23958039e-01 -1.02081627e...            0.0   \n",
              "57118  [[ 1.67145580e-02  6.16340339e-02 -1.64117783e...            0.0   \n",
              "57119  [[ 2.04446822e-01  3.60814929e-01  2.40353718e...            1.0   \n",
              "57120  [[-5.27264893e-01 -3.60895306e-01 -1.11079082e...            0.0   \n",
              "\n",
              "       emotion_Anxiety  emotion_Curiosity  emotion_Desire  emotion_Happiness  \\\n",
              "0                  0.0                0.0             0.0                0.0   \n",
              "1                  0.0                0.0             0.0                0.0   \n",
              "2                  0.0                0.0             0.0                1.0   \n",
              "3                  0.0                0.0             0.0                0.0   \n",
              "4                  0.0                0.0             0.0                0.0   \n",
              "...                ...                ...             ...                ...   \n",
              "57116              0.0                0.0             1.0                0.0   \n",
              "57117              0.0                0.0             0.0                0.0   \n",
              "57118              0.0                0.0             0.0                0.0   \n",
              "57119              0.0                0.0             0.0                0.0   \n",
              "57120              0.0                0.0             1.0                0.0   \n",
              "\n",
              "       emotion_Love & Care  emotion_Neutral  emotion_Relief  emotion_Sadness  \n",
              "0                      0.0              1.0             0.0              0.0  \n",
              "1                      0.0              1.0             0.0              0.0  \n",
              "2                      0.0              0.0             0.0              0.0  \n",
              "3                      0.0              0.0             0.0              1.0  \n",
              "4                      0.0              0.0             0.0              0.0  \n",
              "...                    ...              ...             ...              ...  \n",
              "57116                  0.0              0.0             0.0              0.0  \n",
              "57117                  0.0              0.0             0.0              1.0  \n",
              "57118                  0.0              1.0             0.0              0.0  \n",
              "57119                  0.0              0.0             0.0              0.0  \n",
              "57120                  0.0              0.0             0.0              0.0  \n",
              "\n",
              "[57121 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbcb82d6-1b8b-4acc-8b74-81c48bd380c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>embedding</th>\n",
              "      <th>emotion_Anger</th>\n",
              "      <th>emotion_Anxiety</th>\n",
              "      <th>emotion_Curiosity</th>\n",
              "      <th>emotion_Desire</th>\n",
              "      <th>emotion_Happiness</th>\n",
              "      <th>emotion_Love &amp; Care</th>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <th>emotion_Relief</th>\n",
              "      <th>emotion_Sadness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am getting a lot of weird replies...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>getting lot weird replies</td>\n",
              "      <td>[[ 3.57603505e-02  1.88769430e-01 -5.63014112e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is it illegal?</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>illegal</td>\n",
              "      <td>[[-3.13512266e-01  5.34555972e-01 -5.06467640e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[NAME] just think of how overworked her liver ...</td>\n",
              "      <td>Happiness</td>\n",
              "      <td>name think overworked liver kidneys must</td>\n",
              "      <td>[[-9.83442590e-02  3.89946789e-01 -4.01094072e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>But doing those things makes me feel so.... icky.</td>\n",
              "      <td>Sadness</td>\n",
              "      <td>things makes feel icky</td>\n",
              "      <td>[[ 4.80609946e-02  3.33314270e-01  1.51030645e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shame on you</td>\n",
              "      <td>Anger</td>\n",
              "      <td>shame</td>\n",
              "      <td>[[-8.55700299e-02  2.50925511e-01 -1.43386796e...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57116</th>\n",
              "      <td>Ha, that would be a novel experience. He'd bet...</td>\n",
              "      <td>Desire</td>\n",
              "      <td>ha would novel experience better let deal</td>\n",
              "      <td>[[-2.79613025e-02  1.31248564e-01 -1.78521685e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57117</th>\n",
              "      <td>Very sad. People like this are ruining Aus.</td>\n",
              "      <td>Sadness</td>\n",
              "      <td>sad people like ruining aus</td>\n",
              "      <td>[[ 1.09247044e-01  3.23958039e-01 -1.02081627e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57118</th>\n",
              "      <td>It was worth mentioning anyways, the Packers a...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>worth mentioning anyways packers special kind ...</td>\n",
              "      <td>[[ 1.67145580e-02  6.16340339e-02 -1.64117783e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57119</th>\n",
              "      <td>They want to make gun ownership so expensive a...</td>\n",
              "      <td>Anger</td>\n",
              "      <td>want make gun ownership expensive onerous peop...</td>\n",
              "      <td>[[ 2.04446822e-01  3.60814929e-01  2.40353718e...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57120</th>\n",
              "      <td>Idk if I want [NAME] back but I agree with [NA...</td>\n",
              "      <td>Desire</td>\n",
              "      <td>idk want name back agree name keeps playing le...</td>\n",
              "      <td>[[-5.27264893e-01 -3.60895306e-01 -1.11079082e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57121 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbcb82d6-1b8b-4acc-8b74-81c48bd380c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbcb82d6-1b8b-4acc-8b74-81c48bd380c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbcb82d6-1b8b-4acc-8b74-81c48bd380c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-141a496e-ffba-45b0-b7d1-c0ca1979b3f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-141a496e-ffba-45b0-b7d1-c0ca1979b3f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-141a496e-ffba-45b0-b7d1-c0ca1979b3f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e72392f9-6252-4646-b089-f57d865b7f3d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e72392f9-6252-4646-b089-f57d865b7f3d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 57121,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36424,\n        \"samples\": [\n          \"Tell me about it. Talk about evil icecream haha\",\n          \"It does lol If you delete it off your phone it wouldn\\u2019t trace your estimated location unless it\\u2019s active on it\",\n          \"Anyone who fell for the Lonzo hype from the beginning should slap themselves.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Curiosity\",\n          \"Happiness\",\n          \"Love & Care\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35688,\n        \"samples\": [\n          \"second thought sophomore learning drive based figure baby face distance choice clothing\",\n          \"plan go\",\n          \"nope sadly early 30s\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35689,\n        \"samples\": [\n          \"[[-3.43568265e-01  5.67025840e-02 -2.32801199e-01  3.45742643e-01\\n  -4.58665282e-01 -7.13149644e-03  3.72441500e-01  4.88543123e-01\\n  -1.00179046e-01 -8.58660936e-02  7.26538897e-01  1.59421876e-01\\n   8.15841481e-02  9.33475122e-02 -1.97926551e-01 -2.39183098e-01\\n  -1.68778434e-01  6.15278661e-01  3.61117236e-02 -1.19681701e-01\\n   6.31643757e-02 -6.44134209e-02 -4.28138748e-02 -4.01299506e-01\\n   1.52240247e-01  2.25818470e-01 -4.00571644e-01 -2.92218953e-01\\n  -1.19163141e-01  3.18849981e-01  3.46826613e-01  7.72928298e-02\\n  -1.13648653e-01  5.74290752e-05  1.81998052e-02 -5.08736432e-01\\n   4.32719946e-01  3.97419691e-01 -7.82887265e-02  2.12694928e-02\\n   1.42929181e-01  2.29384065e-01  9.51355398e-02  1.86658621e-01\\n  -1.71190888e-01 -3.13391685e-01 -1.78263497e+00 -5.61012104e-02\\n  -1.25251055e-01 -2.84358263e-02  3.48379940e-01  8.72710198e-02\\n   1.78160265e-01  2.13445947e-01 -2.56140113e-01  4.55230117e-01\\n  -5.93793318e-02  3.16020221e-01  1.98837489e-01  6.82532191e-02\\n   1.06119327e-01 -2.23694086e-01 -3.27481717e-01 -4.98333424e-01\\n   9.97176990e-02  2.67316520e-01  1.89654738e-01  1.11878228e+00\\n  -8.26688558e-02  7.84795731e-02 -1.69539392e-01 -3.50492835e-01\\n   5.10544419e-01  1.78432204e-02  1.80861875e-02 -3.49699587e-01\\n   1.26734614e-01  3.50708842e-01  8.75396281e-02 -2.03202695e-01\\n   5.61032146e-02 -6.25257194e-02  2.23910093e-01 -3.75134014e-02\\n   3.13859805e-02  3.85627627e-01  1.86008886e-01 -4.32970881e-01\\n   7.95015842e-02  6.57820046e-01  5.01689240e-02  1.49349779e-01\\n   3.92628133e-01  3.22921455e-01  8.26441199e-02 -2.61067450e-01\\n   4.92938906e-02 -8.11584964e-02  2.02199876e-01 -9.79409367e-02\\n  -1.90330535e-01 -2.66734421e-01  8.62653404e-02 -3.09547275e-01\\n   1.83544427e-01  6.34712726e-02 -2.37919465e-01  4.61710803e-02\\n  -7.81826973e-02 -2.52770066e+00  5.48139811e-01  2.11326599e-01\\n   7.90084973e-02 -2.09991306e-01 -1.21333331e-01  6.68590128e-01\\n   5.18948078e-01 -1.12606883e-01 -1.96712077e-01 -5.83864450e-02\\n  -2.42573321e-01  2.64683008e-01 -1.76114395e-01  1.59295246e-01\\n   8.10236260e-02  6.25253618e-01 -4.06281836e-02  1.71744034e-01\\n   2.33203590e-01  1.04175359e-02  1.61479831e-01  2.08129033e-01\\n  -3.45813155e-01 -1.61347553e-01 -7.42648318e-02  1.81667730e-02\\n   3.39115143e-01  2.95795381e-01 -2.03128874e-01 -2.14877203e-01\\n  -3.05252463e-01  1.75258651e-01 -3.14560986e+00  7.02881813e-02\\n   8.06850195e-01  1.38533860e-01  5.80710955e-02  4.31179255e-01\\n   6.00426644e-02  3.95725250e-01 -4.31279451e-01  5.06294258e-02\\n  -2.82442570e-03 -1.15939230e-03  2.38932464e-02 -5.25499955e-02\\n  -3.28764021e-01 -4.76963609e-01  3.08659643e-01  4.93988067e-01\\n   3.03284302e-02 -1.06775761e-02  3.63249332e-02 -4.30337675e-02\\n  -3.63761783e-01  3.98858711e-02 -1.62948474e-01 -7.87009522e-02\\n   1.68621868e-01  5.45180105e-02 -1.96146026e-01  4.23536271e-01\\n   3.34611773e-01  2.02648669e-01  8.76511276e-01 -1.20430529e-01\\n   2.78117448e-01  2.74358630e-01 -3.72346461e-01  1.37724698e-01\\n  -2.53583431e-01  2.82408148e-01  1.91997796e-01  2.33567953e-01\\n   2.07639709e-01 -3.35005283e-01  2.00948328e-01  3.08417559e-01\\n   1.57857776e-01 -1.06217317e-01  1.62094831e-04  2.66784400e-01\\n   8.14946815e-02  2.64983326e-01  4.08153564e-01 -7.68653303e-02\\n   1.25171885e-01 -5.87942064e-01  2.79346198e-01  7.13503957e-02\\n   5.45923226e-02 -1.17869318e-01 -1.77092433e-01  2.17850521e-01\\n  -2.49088913e-01  3.42770720e+00 -4.23153713e-02  6.62113279e-02\\n   2.60044128e-01  8.58678162e-01  1.35323480e-01  3.35119128e-01\\n  -4.84099686e-01 -3.68623555e-01 -9.05000418e-02 -2.54136510e-03\\n   3.34571600e-01 -4.82974201e-02 -3.49539220e-01 -1.19019493e-01\\n  -1.24171987e-01  5.64355493e-01 -2.67380595e-01  3.07396531e-01\\n  -3.97796005e-01  4.22689140e-01  6.85097352e-02  2.56723732e-01\\n  -4.30014431e-01 -1.29655147e+00  1.84984922e-01 -5.73697910e-02\\n  -4.53078806e-01  3.03189158e-01 -1.73910841e-01  3.28728765e-01\\n   5.68903703e-03 -4.47570831e-01 -2.60821842e-02 -6.55457675e-02\\n  -1.39866412e-01  2.90481672e-02  2.39772052e-01 -2.73867935e-01\\n  -4.83817667e-01  1.06370196e-01  6.10119641e-01  2.40344703e-01\\n   1.70530975e-01  4.23762381e-01  3.02650809e-01 -3.56635898e-01\\n   1.49914563e-01 -4.50537503e-01 -2.33501911e-01  7.91785344e-02\\n   2.08218291e-01  1.11255869e-01 -2.12297708e-01 -2.64827698e-01\\n  -2.31129795e-01  4.75019217e-01  1.88710943e-01 -2.42402494e-01\\n  -1.12141818e-01 -9.00716037e-02 -1.87964305e-01 -3.94539893e-01\\n   7.15358034e-02 -1.98940352e-01  2.69026309e-01  6.03515282e-02\\n  -3.92334700e-01 -3.78818583e+00  2.57918179e-01  5.67167521e-01\\n   1.39642060e-01  3.32588345e-01 -2.25642353e-01 -9.31085125e-02\\n   2.95555532e-01  2.78743088e-01 -6.41916811e-01  3.26760083e-01\\n   3.53969276e-01 -5.23087159e-02  5.59283085e-02 -4.40105230e-01\\n   5.08501753e-02 -3.47332470e-02 -5.69539703e-02  3.15332294e-01\\n  -2.13038981e-01  1.54210001e-01  7.93320596e-01 -3.29873979e-01\\n  -1.40019536e-01  3.25366020e-01  3.67082655e-01 -4.79704052e-01\\n   1.96351647e-01  3.94815058e-01 -7.36656129e-01 -1.50942236e-01\\n  -2.77709633e-01 -1.46051884e-01  1.42340466e-01 -2.99100190e-01\\n  -3.32796264e+00  1.72657266e-01 -3.33153874e-01 -4.29958850e-01\\n   1.74036145e-01 -4.58822846e-01  5.10381103e-01  1.21745199e-01\\n  -9.83479023e-02  4.35609758e-01 -1.69708073e-01 -2.42625475e-01\\n   3.11469525e-01  1.91320226e-01  7.52225280e-01  1.87784731e-01\\n   4.22658205e-01  2.49032557e-01  2.19784558e-01 -2.71392345e-01\\n   3.25609088e-01  8.91702101e-02  1.63100556e-01 -1.60618916e-01\\n  -7.56953806e-02  7.07519948e-01  4.70607169e-02 -2.52030995e-02\\n  -2.93986142e-01  2.14611918e-01  9.16300118e-02  2.13519126e-01\\n   9.76891667e-02 -1.13651857e-01 -2.64635891e-01 -2.27975160e-01\\n   4.84721482e-01  2.04006836e-01 -5.09552509e-02  4.03127968e-01\\n  -2.41590753e-01  4.30082947e-01 -4.19188768e-01  4.11445469e-01\\n   4.35073406e-01  3.87836754e-01 -1.87016532e-01 -3.62391353e-01\\n   8.92703980e-02 -3.63170266e-01 -9.46410596e-02 -4.01968777e-01\\n   1.02559698e+00 -2.96649665e-01  2.98212707e-01  9.26542804e-02\\n   9.92397368e-02  2.93872878e-02 -6.69240654e-02  2.98767686e-02\\n   5.04408598e-01 -1.84944093e-01  3.81586790e-01  4.74239498e-01\\n   1.30257264e-01 -4.51218963e-01  2.72435337e-01 -4.98854697e-01\\n  -3.63569587e-01  4.05899584e-01  2.98552327e-02  4.44955766e-01\\n  -8.08631629e-03 -6.77005827e-01  3.53832990e-01  1.01947077e-01\\n  -2.75366545e-01  6.48721516e-01  2.56008625e-01  1.53125912e-01\\n   4.64466177e-02  1.25799313e-01 -2.93482482e-01  2.64171124e-01\\n  -2.18714148e-01 -3.16760510e-01  1.06028728e-02  1.33194089e-01\\n  -6.80222452e-01  3.20737362e-01 -8.15464184e-02  5.78935444e-01\\n   2.35627413e-01  2.78168954e-02  1.07866004e-02 -2.31371313e-01\\n   1.97696179e-01 -1.22407305e+00 -1.64815396e-01 -1.53238624e-02\\n  -2.46938974e-01 -7.59062886e-01  4.56531756e-02 -2.60899693e-01\\n  -1.54909074e-01 -2.87729502e-01 -7.35915303e-01  3.59228969e-01\\n  -2.93786794e-01  2.99771547e-01  3.33386391e-01  2.28345349e-01\\n   3.11730832e-01  7.04383314e-01  7.44840741e-01 -8.97601768e-02\\n  -2.47310072e-01  7.44011879e-01  8.16111565e-02  3.45793307e-01\\n   1.42855376e-01  1.33792497e-02  6.08387738e-02 -2.20526919e-01\\n  -6.16484210e-02  4.26398627e-02  1.60937876e-01 -6.48761392e-01\\n   3.29975694e-01 -1.14355631e-01  1.98804662e-01 -2.46759027e-01\\n  -1.57080874e-01 -4.10041749e-01 -1.01762503e-01 -1.96377322e-01\\n  -3.45404595e-01  1.48052529e-01  2.72981018e-01 -4.51267175e-02\\n  -6.48489520e-02 -1.59298494e-01 -8.79866332e-02  4.39417869e-01\\n  -8.00206959e-02  5.68109095e-01 -1.93706036e-01 -5.42540193e-01\\n   4.19777185e-02  6.80256784e-01 -4.03146148e-01 -3.41588497e-01\\n   1.68399140e-01 -1.54734492e-01  1.31515965e-01 -1.77520126e-01\\n  -2.43418708e-01 -1.68828800e-01  7.47402012e-02  1.54761732e-01\\n  -3.12827140e-01  2.44183630e-01 -1.40211284e+00  5.51095366e-01\\n   1.47096395e-01 -6.03042722e-01  2.60534674e-01 -4.19155180e-01\\n  -4.82650042e-01  7.14478135e-01 -3.12166661e-03  4.87396643e-02\\n   7.76808560e-02  6.40968680e-02 -9.95806977e-02  2.86396723e-02\\n   1.74048454e-01 -4.09548134e-02  1.93844497e-01  2.95482576e-04\\n   1.35232285e-01  3.51764709e-02 -8.11342672e-02  6.91577911e-01\\n   2.83927441e-01 -7.62861609e-01 -2.42980585e-01  4.55234855e-01\\n   8.68992209e-02  5.53535521e-01 -3.15545976e-01 -1.42798617e-01\\n   4.80834335e-01 -4.60791104e-02 -7.50854731e-01  7.51525536e-03\\n   4.19081748e-02  5.58295667e-01  2.57897437e-01 -2.49973089e-01\\n   1.22556444e-02 -1.06519997e-01  3.29745710e-01 -1.95692420e-01\\n   2.50843346e-01 -3.65471058e-02  4.19411063e-01  4.36573327e-01\\n  -1.10869050e-01  3.34863275e-01  2.38753408e-01 -3.59210998e-01\\n  -8.41410995e-01 -1.01752095e-01  6.12311400e-02 -1.04190536e-01\\n   2.43014395e-01 -1.13611594e-01  5.40147647e-02 -1.65281445e-01\\n  -3.59983742e-01  1.90500051e-01 -4.23740447e-01 -1.24196038e-01\\n  -1.77341755e-02  4.67110686e-02 -6.13740563e-01 -5.23591518e-01\\n   2.09634483e-01 -3.05103421e-01 -2.76904464e-01  1.25086606e-01\\n   3.05572420e-01  2.02333540e-01 -6.26233965e-03  3.66380841e-01\\n  -2.62516826e-01  1.99823752e-01  3.10209915e-02 -2.73832709e-01\\n  -2.81643849e-02 -4.59447801e-01 -1.42793238e-01 -5.64883232e-01\\n  -2.24669576e-01  4.79025483e-01 -5.75470984e-01  1.78253338e-01\\n   3.71854782e-01 -1.06785856e-01 -2.86910653e-01 -6.23879917e-02\\n  -3.38596314e-01 -3.80642086e-01  1.86544552e-01 -3.38376999e-01\\n  -2.45458007e-01 -1.15419149e-01  1.61795750e-01  2.09225804e-01\\n  -4.04625624e-01  2.59394467e-01 -5.68531305e-02  3.56047660e-01\\n   2.49017298e-01  1.99998438e-01  1.43587813e-01  4.19848323e-01\\n   3.57520759e-01  3.65489572e-01 -4.49442178e-01 -3.13762009e-01\\n  -3.43953878e-01 -8.30000341e-02 -6.07848167e-01  1.62099674e-02\\n   3.76193076e-02 -1.73448041e-01  1.88134387e-01  7.00023994e-02\\n   1.63195539e+00  3.35741132e-01  2.19622701e-01  6.77100420e-02\\n   4.70221996e-01  1.81192592e-01 -6.48559451e-01  2.65174434e-02\\n  -5.06980002e-01  7.69596815e-01  3.53371531e-01  1.64040968e-01\\n  -2.68553138e-01  1.51252970e-01  2.55956769e-01  4.02217239e-01\\n   6.55152798e-02 -4.42966461e-01 -3.59080076e-01  4.14114058e-01\\n  -5.22217631e-01  1.98254734e-01  2.88253218e-01  1.81655735e-02\\n   3.96369398e-01  5.00950336e-01  9.18663889e-02 -4.47821528e-01\\n   3.91409993e-02 -6.73431680e-02 -1.67496338e-01 -2.61421114e-01\\n   2.87093639e-01  3.78416032e-01 -1.10721543e-01 -3.67328882e-01\\n   1.64969370e-01 -1.75621927e-01 -3.55996162e-01  2.08088562e-01\\n   2.11728230e-01 -3.91831771e-02  9.13632274e-01  7.62023255e-02\\n  -2.58657411e-02  5.73260665e-01 -2.18611166e-01 -2.57735670e-01\\n   6.11851931e-01  3.03819478e-01  1.82805106e-01 -5.38128495e-01\\n  -4.07635659e-01 -4.32038605e-01 -2.64363408e-01 -3.31459373e-01\\n  -1.98434275e-02 -1.52774766e-01 -1.43137053e-02  3.29012066e-01\\n  -1.64215028e-01  1.33156449e-01  1.45866886e-01 -6.88264072e-02\\n  -8.01320188e-03  9.02459323e-02 -7.20771968e-01 -3.20289612e-01\\n   5.71843028e-01  1.79222882e-01 -1.22225750e-02  8.58532041e-02\\n  -1.27080306e-01 -1.00233227e-01  2.34869212e-01 -1.14121094e-01\\n   1.42061174e-01 -1.45696700e-01 -3.62905383e-01 -2.83033299e+00\\n   1.38014793e-01 -5.64384088e-02  2.21419215e-01  1.11286521e-01\\n   2.80493081e-01  7.27917254e-02  1.73679769e-01  2.35091344e-01\\n  -3.94885480e-01  6.20206408e-02  4.29059744e-01 -1.53063521e-01\\n  -1.85673743e-01 -1.61639564e-02  3.72095853e-01  1.22456625e-02\\n  -5.89789450e-03 -3.86713475e-01 -8.57035741e-02  1.60994649e-01\\n   1.12079941e-01 -6.97789907e-01 -4.41107929e-01 -6.72154799e-02\\n  -5.83917350e-02  3.60703558e-01 -3.75223517e-01 -2.37084687e-01\\n   4.64628398e-01 -1.86066002e-01  1.55082181e-01  1.44478932e-01\\n   2.51082063e-01  1.13424703e-01 -3.17960352e-01 -3.81995216e-02\\n   3.27815950e-01 -1.95529416e-01  1.35917962e-01 -2.13937894e-01\\n   3.83216292e-01  4.75769192e-02  2.63530493e-01 -1.07415229e-01\\n  -6.00231662e-02  1.79689646e-01 -4.14131582e-01  4.86287147e-01\\n  -5.82551718e-01 -1.52444720e-01 -6.54370338e-02  2.23789468e-01\\n   4.05300036e-02 -1.38011321e-01  3.87607008e-01  3.16716015e-01\\n   1.77501783e-01 -3.51965427e-03 -6.52382731e-01 -8.57992321e-02\\n   4.37815160e-01 -2.91816741e-01  3.49634290e-02  6.90453649e-01\\n  -2.89926559e-01 -3.32116723e-01 -2.13251144e-01 -2.29737177e-01\\n  -1.35464057e-01 -4.71768916e-01 -6.55468047e-01  6.31652027e-02\\n   2.56113708e-03  2.22827137e-01  4.99108344e-01  1.16850272e-01\\n  -1.42754480e-01  3.23817641e-01  3.36096659e-02  7.02765360e-02\\n  -1.38434425e-01 -3.36300820e-01 -1.20617449e-04 -1.70998931e-01\\n  -7.55091190e+00 -1.77186370e-01  6.51531741e-02 -2.87121832e-01\\n   1.74666464e-01 -2.23395571e-01 -7.77246058e-02 -1.27264708e-01\\n  -6.53038472e-02  2.99280763e-01  5.12145698e-01 -2.99744964e-01\\n  -3.56952012e-01 -5.69918826e-02  1.05937257e-01  1.75166756e-01]]\",\n          \"[[-2.94480234e-01 -2.44795512e-02 -2.36241110e-02 -2.30456352e-01\\n  -2.54354388e-01  6.27304837e-02  2.11865872e-01  5.24230182e-01\\n  -4.61879432e-01 -1.82008401e-01  2.53535211e-02  4.78944033e-02\\n  -4.78906453e-01  4.01701212e-01 -2.79603489e-02 -1.19940810e-01\\n  -5.81981838e-01  9.07343805e-01  1.69039488e-01  1.56181857e-01\\n   2.87735641e-01 -9.86689329e-02 -2.09565878e-01 -4.32041556e-01\\n   2.89688289e-01 -3.14025246e-02  1.74205959e-01 -2.42086798e-01\\n  -1.82179034e-01 -1.35153383e-01  1.56648144e-01  2.93051869e-01\\n  -5.89860678e-02 -3.48074228e-01  2.64210165e-01 -5.81810415e-01\\n  -1.13526933e-01  6.86348677e-02 -1.94227099e-02  5.72895184e-02\\n  -1.42369851e-01  3.78018379e-01  2.32003838e-01 -4.05489236e-01\\n  -2.33492851e-02 -9.06225294e-02 -2.40289021e+00 -8.48816857e-02\\n  -2.06260040e-01 -2.73154795e-01 -7.85798207e-02 -5.37716508e-01\\n   3.07144642e-01  2.36808077e-01  1.78620338e-01  4.22663927e-01\\n  -4.16726142e-01  3.68742824e-01 -7.02534094e-02 -8.29875469e-04\\n   3.86646032e-01 -1.77889735e-01 -2.11529061e-02 -4.44498509e-01\\n   1.88813180e-01  2.32220173e-01  6.37779683e-02  3.85119945e-01\\n  -4.21691924e-01  1.28364816e-01 -4.25361484e-01 -1.93664938e-01\\n   1.22558624e-01 -6.04345687e-02  1.21920049e-01 -3.49857450e-01\\n  -7.18444884e-02  4.69695807e-01 -2.64005303e-01 -3.81861031e-01\\n   8.89717489e-02  1.28980041e-01 -2.20282584e-01  1.75779253e-01\\n  -5.66171668e-02  5.45949876e-01 -1.46411106e-01 -5.66606522e-01\\n   5.89537203e-01  9.47774231e-01  1.57115296e-01 -2.03173399e-01\\n   2.62162983e-01  3.27975214e-01  4.82794374e-01  5.95587045e-02\\n  -3.41038816e-02  3.39448214e-01  1.96713164e-01 -1.65461272e-01\\n  -2.91533232e-01 -2.86693692e-01 -1.63361549e-01 -1.48131326e-01\\n   5.13015330e-01 -3.84455144e-01  2.26576477e-01  1.43220022e-01\\n   2.88283110e-01 -3.02611184e+00  1.08236209e-01  3.29495460e-01\\n   6.50191233e-02 -1.40141901e-02 -2.66375422e-01  2.48896241e-01\\n   6.09044671e-01 -2.33782679e-01  2.38288969e-01  2.73352116e-01\\n  -2.86491036e-01  2.16271907e-01 -4.62047383e-02 -1.91992044e-01\\n  -5.73117435e-02  3.72230262e-01 -2.23555580e-01  1.80415705e-01\\n  -9.53278840e-02 -2.82319859e-02 -3.01664025e-01  6.37729228e-01\\n  -4.20990586e-01 -4.61715534e-02 -2.31730416e-02  3.61066088e-02\\n   3.25581312e-01 -2.15932176e-01 -4.31451686e-02  1.23576894e-02\\n  -5.15353978e-01  9.18383598e-02 -3.31974411e+00  2.61721939e-01\\n   2.95860827e-01 -2.46689051e-01 -4.80229288e-01  4.02815968e-01\\n  -1.56513005e-01  2.50184536e-01  9.46438685e-02 -3.24179232e-01\\n   9.83088315e-02 -2.60092258e-01 -3.99711467e-02  3.61046493e-02\\n   8.16368610e-02 -7.53760815e-01  1.71565354e-01  4.87917423e-01\\n   4.61250722e-01  9.49281156e-02 -1.24061622e-01 -2.60121562e-02\\n  -1.91292092e-01  1.38096735e-02  2.30865955e-01  7.89037123e-02\\n   2.32743114e-01  3.47304828e-02 -1.88888721e-02  1.97198734e-01\\n   6.55336022e-01  2.97070384e-01  5.18292904e-01  1.16133079e-01\\n  -3.04251075e-01  3.07937503e-01  3.50493670e-01  2.03903705e-01\\n   8.54038298e-02  3.12620342e-01  9.36750546e-02  3.55539650e-01\\n   3.28002214e-01 -2.78870873e-02  4.34054911e-01 -4.29411307e-02\\n   3.08681905e-01  1.38412699e-01 -3.66800278e-02  1.69565603e-02\\n   2.66671777e-01  4.49949831e-01  3.16719890e-01  6.41418025e-02\\n   1.77990198e-01 -4.18232262e-01  5.52665353e-01 -1.00537598e-01\\n   1.31620526e-01 -1.49923936e-03 -2.24585421e-02  5.72592735e-01\\n  -5.36506772e-01  3.92807221e+00 -1.04163423e-01  3.31209302e-02\\n   1.21325739e-02  2.50895053e-01  1.44287065e-01  2.10157931e-01\\n   2.53312010e-02 -4.88184929e-01  1.70274794e-01 -3.57487313e-02\\n   1.71236798e-01 -1.33096501e-02 -5.05963743e-01 -4.97974843e-01\\n   1.81771331e-02  5.95368505e-01  2.87977964e-01  2.95519203e-01\\n  -2.23906189e-01  2.70832241e-01 -2.59302944e-01 -5.78029156e-01\\n  -1.80641085e-01 -1.26203573e+00  2.43113875e-01 -3.79590057e-02\\n  -4.40618128e-01  2.32847810e-01 -9.13066864e-02 -6.59070313e-02\\n   1.95062861e-01 -3.29245925e-01  1.67105734e-01  3.39621097e-01\\n   5.52644804e-02  4.97989357e-01  1.13139771e-01 -1.41716078e-01\\n  -2.39853039e-01 -4.89236504e-01 -9.66513604e-02 -2.99426503e-02\\n  -3.88865530e-01  1.60015583e-01  2.34866977e-01 -5.67995727e-01\\n  -6.18970506e-02 -1.70652539e-01 -1.57615468e-02  2.10473061e-01\\n   1.85613915e-01  6.24333918e-01 -1.25596076e-01 -2.72943079e-01\\n  -7.04269856e-02  1.62296519e-02  2.59464175e-01 -1.54862940e-01\\n  -1.19010225e-01  1.63472801e-01 -1.98654503e-01 -2.48865336e-01\\n   1.14317909e-02 -2.80273795e-01 -1.63814440e-01  2.52449423e-01\\n  -2.36723125e-01 -3.90166044e+00  2.72811621e-01  3.20581138e-01\\n   3.12642366e-01  2.65189201e-01  2.47258767e-01 -1.72777355e-01\\n   2.34695166e-01  4.54057455e-01  7.91132003e-02  2.70850420e-01\\n  -2.27525905e-02  2.30789874e-02  2.55006045e-01  7.19726235e-02\\n   4.73703474e-01 -1.80094361e-01  1.97769888e-02 -2.19221972e-02\\n   1.63237274e-01  3.70450795e-01  3.44467580e-01 -1.73615307e-01\\n  -2.07406133e-01  6.31483793e-01 -7.46995211e-03 -3.89160961e-01\\n   2.20637787e-02  3.61497015e-01  2.05088273e-01  5.38989156e-02\\n   7.21065998e-02  1.02491044e-01  1.05263099e-01 -1.66133836e-01\\n  -3.14898801e+00  1.03320003e-01  3.98470536e-02 -4.93595064e-01\\n   3.82355273e-01 -3.72504920e-01  1.50986955e-01 -2.47611865e-01\\n  -1.33693188e-01  2.47625157e-01  1.71569854e-01  4.60592024e-02\\n   1.82971269e-01 -2.83717513e-01  1.80243224e-01  1.72203615e-01\\n   4.87317502e-01  2.06584781e-02 -1.68494388e-01  7.93994367e-02\\n   4.44393158e-02  2.29454204e-01 -1.46134555e-01 -1.39721125e-01\\n   7.34537095e-02  2.40977526e-01 -4.61267412e-01 -1.26464099e-01\\n  -6.25187755e-01 -2.33841404e-01 -1.39188059e-02  7.09726363e-02\\n   1.11645728e-01  2.04630539e-01 -2.96298474e-01 -7.38693103e-02\\n   1.71254411e-01  1.82365656e-01  2.71905452e-01  1.33110225e-01\\n   5.10985926e-02  4.23815578e-01 -3.56343806e-01  3.31219524e-01\\n   2.25167513e-01  3.94161463e-01  1.14894472e-01 -4.18631434e-01\\n  -4.03278589e-01 -8.21424276e-02 -1.05636090e-01 -3.44503015e-01\\n   1.09324861e+00 -7.07816482e-02  3.18530262e-01 -1.16650052e-01\\n   2.58782029e-01  2.35398099e-01 -3.27683873e-02 -2.26327255e-02\\n   7.93691397e-01 -1.16606191e-01 -5.31975701e-02  3.36166412e-01\\n   1.08343437e-01 -5.17931163e-01 -8.54624435e-03 -6.96564376e-01\\n   4.52511348e-02 -3.53273749e-03 -2.54856467e-01  1.24721304e-01\\n  -8.93448666e-02 -8.23585451e-01 -1.01726994e-01  2.34485775e-01\\n  -1.70171142e-01  2.70506948e-01  2.75812119e-01 -3.82445246e-01\\n  -3.16797882e-01 -2.01698188e-02 -6.51936680e-02  3.57122093e-01\\n  -3.84257101e-02  4.29228365e-01  1.36668198e-02 -1.63049344e-03\\n  -3.11277807e-01 -3.43542621e-02 -2.32560813e-01  1.59869432e-01\\n  -1.25456214e-01  9.16778669e-02  9.85856727e-02  5.51967435e-02\\n   2.81818867e-01 -4.74491447e-01  1.19316019e-01 -6.63753599e-02\\n  -2.21714348e-01 -1.22679293e-01 -3.52618605e-01  2.03539208e-02\\n  -7.39240348e-02  1.24055043e-01 -5.25291860e-01  2.06263825e-01\\n   1.55889779e-01  2.76298612e-01  5.48634708e-01  2.77169585e-01\\n  -3.58752944e-02  6.09766662e-01  6.53473496e-01  1.06793709e-01\\n   9.67571065e-02  1.76857650e-01  2.18297720e-01  2.65053689e-01\\n  -1.67954624e-01 -2.23881260e-01 -4.53908145e-01 -8.21867809e-02\\n  -4.02479023e-02  9.71238315e-02  8.21178854e-02  6.62703291e-02\\n  -3.87790352e-01  1.14728719e-01 -1.72095001e-01 -1.69622719e-01\\n  -2.65474916e-01 -5.40131450e-01 -1.51534379e-03 -3.32996964e-01\\n  -4.45363045e-01  3.39195371e-01 -1.38596535e-01  1.74507648e-02\\n   6.47649318e-02 -2.52636313e-01 -1.22317433e-01  4.79556948e-01\\n  -1.08647972e-01  4.48250979e-01  3.09054345e-01  1.71354294e-01\\n   1.90059841e-01  2.14269131e-01 -9.23290104e-02 -5.26910722e-01\\n   2.07996175e-01 -3.75662833e-01 -2.30582654e-02  8.42794552e-02\\n  -2.08710447e-01 -1.43276617e-01 -3.20945010e-02  1.37398124e-01\\n   1.35156661e-01  1.35919034e-01 -1.49166417e+00  4.56291586e-02\\n   6.37962222e-02 -3.99743527e-01  5.77875972e-01 -1.20825380e-01\\n  -5.65657020e-01  7.26816356e-01  2.88670778e-01 -5.30902632e-02\\n  -2.17702836e-01 -2.68262714e-01 -5.26469171e-01  4.26502794e-01\\n   1.55755773e-01  2.02655271e-01  3.87938112e-01 -3.92879426e-01\\n  -1.47483438e-01  4.10231054e-01  2.88739681e-01  6.14610672e-01\\n  -2.68668626e-02 -3.26482743e-01 -1.02086127e-01 -2.66103864e-01\\n  -2.25839779e-01  4.12127852e-01 -3.31802011e-01  6.08512722e-02\\n   1.84164554e-01 -1.68330893e-01 -6.49362445e-01  3.91001105e-01\\n   1.23006783e-01  2.34018072e-01  3.87679219e-01  2.74274826e-01\\n   3.89424890e-01 -2.11005837e-01 -2.96611816e-01 -8.87970999e-02\\n   1.37621790e-01 -1.66246757e-01  5.01055002e-01  1.53481171e-01\\n  -2.12839454e-01  2.60449331e-02  4.33190316e-01 -5.73651493e-02\\n  -3.45796645e-01 -2.08638668e-01  8.45144838e-02 -2.13744864e-01\\n   2.59016633e-01  3.90119255e-01 -1.40527040e-01  2.01507375e-01\\n  -2.07498044e-01  2.46460125e-01  2.15921745e-01 -3.86307016e-02\\n   2.74725884e-01  3.47501427e-01 -1.75779670e-01 -5.62502861e-01\\n   4.59432960e-01 -1.91728234e-01 -1.32131502e-02  2.92511106e-01\\n   5.00955820e-01 -8.43027681e-02 -2.32890755e-01  2.30850458e-01\\n   2.17239395e-01 -1.54970139e-01  1.55881688e-01 -2.57555068e-01\\n   2.73766816e-01 -5.09420633e-01 -4.05414194e-01 -5.92540979e-01\\n  -1.52470350e-01  4.30788428e-01 -1.26387060e-01  1.71809703e-01\\n   3.21347505e-01  3.01610410e-01 -3.40487212e-02  2.67747510e-02\\n  -4.05013919e-01 -3.26731920e-01 -9.69357789e-03 -4.96727228e-03\\n  -1.34963840e-01 -3.76605153e-01  1.40425593e-01  2.31154636e-02\\n  -1.39900640e-01  1.40432999e-01 -1.81353971e-01  3.97587299e-01\\n   2.46076614e-01  9.89066511e-02  1.99710861e-01 -9.58253294e-02\\n   2.13883594e-01  5.48063874e-01 -3.68981302e-01 -1.08317651e-01\\n   2.02905029e-01  1.79135188e-01 -1.63708687e-01 -4.04590845e-01\\n  -9.26759169e-02 -5.03195301e-02  2.06404403e-01 -1.45468161e-01\\n   2.00936270e+00  4.78341542e-02 -1.38829708e-01  1.18211851e-01\\n   5.14453113e-01  2.40881532e-01 -1.43109724e-01  1.14514440e-01\\n   2.79650800e-02  3.45877498e-01  3.00972909e-01 -3.68078500e-02\\n   4.58811894e-02 -1.05883747e-01  4.81334627e-01 -4.84413505e-02\\n  -4.14930582e-01 -6.63420260e-01 -3.37242067e-01  2.39396803e-02\\n  -4.49201792e-01  1.51002809e-01 -1.09026954e-02  6.27536923e-02\\n   2.82967508e-01  3.06440592e-01 -2.23153487e-01 -3.72774869e-01\\n  -2.74411052e-01 -1.96378902e-01 -2.45888785e-01 -2.07661271e-01\\n   5.05903065e-01  3.90125394e-01  1.44456327e-01 -1.19372159e-02\\n   3.31021100e-02 -9.81511995e-02 -2.16894120e-01  2.50553280e-01\\n  -6.44795075e-02 -2.23987669e-01  8.38606298e-01 -7.10114762e-02\\n   1.84401378e-01  5.02632499e-01  1.13013208e-01 -2.80472577e-01\\n   4.48237091e-01  2.62494922e-01 -3.03554773e-01 -3.23421866e-01\\n  -7.58659691e-02  1.50257111e-01 -3.74816284e-02 -1.73413202e-01\\n   1.88515157e-01 -7.77919665e-02  1.55133873e-01  3.79978418e-01\\n  -2.15666920e-01  1.42451838e-01  1.38064548e-01 -3.67074877e-01\\n   7.09677115e-02  7.30294734e-02 -3.49290162e-01  5.44436574e-01\\n   2.05337644e-01 -4.47603967e-03  2.40996242e-01  1.54381886e-01\\n  -1.06115595e-01  1.09656945e-01  2.02758685e-01 -1.86795339e-01\\n   4.53025311e-01 -2.17533395e-01 -1.06666863e-01 -3.12578416e+00\\n   2.27943268e-02  4.23236519e-01 -2.64835712e-02 -1.28262118e-01\\n   6.99226558e-01 -2.16075569e-01  7.69021921e-03 -7.90899992e-02\\n  -5.00566959e-01 -2.46445969e-01  5.16885519e-01 -6.61576986e-02\\n   1.25645325e-02  3.43355276e-02  1.98562033e-02 -3.03920388e-01\\n  -5.13164759e-01 -3.54885578e-01 -3.69657069e-01 -3.12020332e-01\\n   1.22724339e-01 -3.03267241e-01 -2.94182301e-01 -6.85745716e-01\\n   1.90600052e-01  8.43676925e-02 -2.58578837e-01  1.25998497e-01\\n   1.72066718e-01 -2.71872401e-01  1.47005245e-01  5.84772229e-01\\n   4.79051054e-01 -4.51232418e-02  4.01626825e-02 -1.49718583e-01\\n  -4.06410098e-01 -1.61756128e-01  1.44766286e-01 -1.03468649e-01\\n   3.89856249e-01 -2.17382669e-01  2.32583538e-01 -1.14087671e-01\\n  -2.17751563e-01 -2.27568336e-02 -8.28009471e-02  4.36337739e-01\\n  -1.39533862e-01  2.80080065e-02  1.01697724e-02  3.40449885e-02\\n  -2.86649495e-01 -8.25460535e-03  7.57491961e-02 -2.65015960e-02\\n   2.83563882e-01 -4.72998545e-02 -3.56496781e-01  3.17826569e-01\\n   5.29899597e-01 -4.11272615e-01  2.25704357e-01  6.99316859e-02\\n  -5.32690406e-01 -2.31944486e-01 -1.40122026e-01  3.34351093e-01\\n  -1.42146908e-02 -3.74432176e-01 -2.57891536e-01  4.74773228e-01\\n   1.75987303e-01  7.51552507e-02 -1.87373579e-01  1.06308743e-01\\n   2.49195620e-01 -1.08636722e-01  1.16320401e-01  3.28368604e-01\\n   2.53909200e-01 -2.89821506e-01  3.68381292e-01  2.45182589e-01\\n  -7.44514704e+00 -1.31311402e-01 -6.74774572e-02 -1.44637063e-01\\n   1.58395410e-01 -4.46499586e-01  1.30059719e-02 -9.12812501e-02\\n  -2.72364289e-01  1.10209495e-01  4.50940311e-01 -3.02301109e-01\\n  -3.44278693e-01 -1.41110957e-01  5.55135727e-01  4.38936532e-01]]\",\n          \"[[ 1.20849470e-02  9.29291174e-02  1.65451795e-01 -9.82783362e-03\\n  -1.85235944e-02 -4.47622240e-01  2.97093481e-01  7.04439521e-01\\n   1.31836250e-01  5.80024123e-02  4.59339082e-01  6.51436672e-03\\n   1.41360998e-01  4.70081568e-01 -2.53325105e-01  9.43010524e-02\\n  -4.28460002e-01  2.30492651e-03  2.72212356e-01 -1.34599552e-01\\n   2.99461901e-01 -2.64884859e-01 -5.65538630e-02 -7.67571181e-02\\n  -1.65515497e-01 -3.28899980e-01 -1.86438024e-01 -1.75471306e-01\\n   8.65453854e-02  5.32799661e-01 -3.86589110e-01  2.77143419e-01\\n  -1.06560225e-02  2.31565475e-01  5.49969196e-01 -2.16710009e-02\\n   2.00853184e-01  5.78862578e-02  1.32894263e-01  1.23168230e-01\\n  -7.95660913e-02  6.17810860e-02  8.85631323e-01 -2.83742368e-01\\n  -1.02923311e-01 -4.65627968e-01 -2.54326749e+00 -1.58075392e-01\\n  -5.96684031e-02 -3.38902205e-01  4.92651701e-01 -4.39480424e-01\\n   5.93051314e-04  1.50975063e-02 -1.39164925e-01  2.88870603e-01\\n  -5.12241721e-02  3.41975629e-01  2.06607133e-01  5.85611820e-01\\n   4.51093942e-01 -5.12759924e-01 -2.57371545e-01  4.28209126e-01\\n  -4.66940664e-02  2.30352342e-01 -2.27161944e-01  4.78445172e-01\\n  -1.87385410e-01  7.08569705e-01 -5.12595654e-01 -2.02155679e-01\\n   7.93398261e-01  1.09674007e-01 -2.22388938e-01 -2.59466887e-01\\n   3.23998749e-01  2.52274960e-01 -1.29382923e-01 -3.49699199e-01\\n   3.31200480e-01  2.99195439e-01  1.80644512e-01  9.92123336e-02\\n   1.90129489e-01  6.86397195e-01 -1.71566188e-01 -6.31820619e-01\\n   3.18121612e-01  5.42510569e-01  1.76867545e-01 -2.80489743e-01\\n   1.13840893e-01  1.39596358e-01  3.44876535e-02 -1.39370233e-01\\n   1.68326311e-02  4.87270415e-01 -3.30360234e-02  1.50895819e-01\\n   5.96747160e-01  3.89268279e-01  7.73495585e-02 -5.35452366e-01\\n   3.54260117e-01 -1.64420798e-01  2.73529757e-02  1.09298490e-01\\n   2.27776185e-01 -2.50085163e+00  4.78987098e-01  5.61156154e-01\\n   3.68848555e-02  1.17705949e-01 -2.96053141e-01  1.41911745e-01\\n   3.92360717e-01 -3.31573516e-01  3.58295679e-01  1.47952482e-01\\n  -5.47171474e-01  3.95400912e-01 -1.55940518e-01 -2.25995257e-01\\n   1.53786466e-02  3.96388799e-01  1.37689173e-01  9.34722088e-03\\n   2.69867778e-01  2.44512796e-01  2.38312222e-03  4.32807714e-01\\n  -3.48037444e-02 -6.38930738e-01 -3.37337136e-01  1.72380030e-01\\n   2.39501894e-01  6.12316020e-02 -3.23179066e-01  6.86826110e-02\\n  -5.50456703e-01 -1.36137500e-01 -2.89188337e+00  2.95506567e-01\\n   3.25375468e-01  2.58746713e-01  8.64395499e-02  1.60604358e-01\\n   5.18224835e-02  2.19727844e-01  7.53593817e-02 -1.56419463e-02\\n   1.21917680e-01  5.29881492e-02 -3.68538946e-01 -4.97902960e-01\\n  -4.02380750e-02 -6.34416342e-02  2.62631118e-01  4.04249549e-01\\n   8.34167004e-02 -8.27532634e-02 -8.41732025e-02 -1.31608084e-01\\n  -4.10407819e-02  1.01598985e-01  4.16374475e-01  3.31948698e-03\\n   4.09666777e-01 -2.82642264e-02 -1.91776827e-02  8.28928649e-02\\n   4.22199905e-01  2.65620910e-02  1.38084903e-01 -1.10898137e-01\\n   5.04461825e-01  4.87372667e-01 -2.57252216e-01  9.17578116e-02\\n   1.39958665e-01 -1.86290383e-01  4.58402559e-02  1.79340407e-01\\n   1.86490983e-01 -4.49052125e-01  2.71329373e-01  1.86340809e-02\\n   7.32116401e-02  1.91006467e-01 -2.22491220e-01 -2.13029742e-01\\n   2.20409095e-01  3.53544503e-01  3.47883135e-01  1.51557833e-01\\n   4.39768642e-01 -6.18083954e-01  2.11514652e-01  2.16993496e-01\\n   3.48779857e-01  2.33183265e-01  1.09924644e-01  2.23502055e-01\\n  -1.47633895e-01  3.94774055e+00  1.27614662e-01  3.45397949e-01\\n   3.88188124e-01  1.55697569e-01 -1.21619515e-01 -4.43618819e-02\\n  -1.98277146e-01 -1.09446473e-01 -3.03210169e-01 -1.00702405e-01\\n   6.54737175e-01  1.25451192e-01 -4.93084967e-01  4.07403648e-01\\n  -2.13116296e-02  6.40906453e-01 -2.56018341e-01  3.62509191e-02\\n  -2.98602469e-02 -4.19774890e-01 -3.01973447e-02 -3.96263540e-01\\n  -2.15974063e-01 -1.45650935e+00  2.01752067e-01 -2.23036394e-01\\n  -3.98683786e-01  6.32367253e-01 -2.16743842e-01  1.50458943e-02\\n   1.11650243e-01 -2.80262440e-01  1.40082091e-03  1.55689806e-01\\n   5.81050038e-01  1.27136841e-01  3.41948807e-01  2.41583548e-02\\n  -2.12779865e-01  2.39927068e-01  2.87058234e-01 -4.94793922e-01\\n  -1.07920587e-01  2.71306306e-01  3.16047341e-01 -1.00513272e-01\\n   1.67910427e-01 -3.62485379e-01 -2.51112133e-01 -1.01321816e-01\\n  -2.67018229e-01  3.99284542e-01 -3.53736699e-01 -8.16440284e-01\\n   5.56057692e-03 -3.80939335e-01  5.36657155e-01  1.98468134e-01\\n  -3.95676821e-01 -3.35532635e-01 -1.39830023e-01 -3.97224426e-01\\n  -4.40290153e-01 -7.08630010e-02 -1.83945015e-01  1.36542112e-01\\n  -3.27790171e-01 -3.58723402e+00  3.98739070e-01  2.54540086e-01\\n   3.28292370e-01  1.89929038e-01 -9.83511508e-02  2.21738636e-01\\n   6.40634000e-01  1.24946453e-01 -5.54446638e-01  5.44708222e-02\\n  -4.56761986e-01 -1.94790050e-01  2.03043133e-01  6.10951781e-02\\n   8.51751938e-02 -9.42536145e-02  1.53488383e-01 -1.10577866e-01\\n   7.33539611e-02  6.11848712e-01  3.35144937e-01 -3.90241176e-01\\n   4.14089710e-01 -1.91860020e-01 -2.51480639e-01 -4.98222560e-01\\n  -3.54527861e-01  4.69314121e-02 -2.62225568e-01  1.21328436e-01\\n  -2.23338425e-01  4.74757999e-02 -1.22120708e-01 -2.04384029e-01\\n  -3.26790524e+00  1.24419570e-01 -7.57877171e-01 -4.07236695e-01\\n   1.02739722e-01 -4.08443600e-01  3.21039259e-01 -1.03602819e-01\\n  -2.18475029e-01  8.90228152e-02  1.62371904e-01  2.54591167e-01\\n  -3.34942728e-01  4.45452631e-01  4.20195460e-01  4.06463370e-02\\n   6.91615283e-01  5.17273962e-01 -2.34652489e-01 -1.32357940e-01\\n   1.53928086e-01  1.88741311e-01  1.27346545e-01  1.48531012e-02\\n   5.15938640e-01  2.05431461e-01 -4.87633020e-01 -3.38612586e-01\\n  -6.08217955e-01  3.01815689e-01  2.61266232e-01 -2.87824199e-02\\n  -1.21471107e-01  9.93356854e-02 -4.28997904e-01 -1.42161548e-02\\n   4.06425238e-01  1.69625565e-01  6.54730260e-01  4.14062679e-01\\n   2.61087358e-01  6.00714743e-01 -2.60681391e-01  4.01440710e-01\\n   7.77605653e-01  5.56466728e-02 -1.66832209e-02 -3.18183869e-01\\n  -1.22685395e-01  1.23292878e-01  1.15020171e-01 -6.67792186e-02\\n   6.31478012e-01 -3.79490815e-02  1.30412370e-01 -4.95765954e-01\\n   2.45174825e-01  2.59624094e-01  7.45025203e-02 -2.18783692e-02\\n   6.50729716e-01  2.32543871e-01  5.25774956e-01  1.17498219e-01\\n  -3.56085479e-01  1.95889883e-02  5.92313744e-02 -5.31599402e-01\\n  -1.62581533e-01  1.70376420e-01 -5.20770811e-03  2.07011133e-01\\n  -1.18257135e-01 -1.12995124e+00 -3.93538401e-02  2.64014751e-01\\n  -1.33428738e-01  6.81897700e-01 -8.54207873e-02  7.08670095e-02\\n   5.60514964e-02  5.50789684e-02 -4.17996526e-01  5.15006125e-01\\n  -3.00157785e-01  1.59639657e-01 -2.98409224e-01  3.97662856e-02\\n  -1.53804228e-01 -2.00041771e-01 -1.61539435e-01  3.41738880e-01\\n   2.43700683e-01 -2.87109464e-02  7.42928162e-02  3.22669387e-01\\n   1.67575404e-01 -9.60502386e-01  4.12508488e-01 -1.00573160e-01\\n  -2.02094555e-01 -1.31831765e-01 -4.16670889e-01  1.38215944e-02\\n  -5.78040302e-01 -5.59783876e-01 -3.22696865e-01  4.70279157e-01\\n   1.70569941e-02 -1.50266796e-01  3.04274470e-01 -2.82031476e-01\\n   6.11012429e-02 -2.06136107e-02  6.93220615e-01 -1.68826878e-01\\n  -4.15341705e-02  6.78814352e-01 -1.10538810e-01  1.91581368e-01\\n   1.30376428e-01 -5.79891242e-02 -4.19275761e-02 -1.60945490e-01\\n  -6.55624509e-01 -1.25706986e-01 -4.35104109e-02 -1.69711173e-01\\n  -3.96903515e-01 -1.20777063e-01 -3.12681943e-01 -1.59843802e-01\\n  -8.14946294e-02 -3.41244638e-01 -2.61000514e-01 -2.30449423e-01\\n   1.95968211e-01  3.72405648e-02  1.40237749e-01 -2.77793825e-01\\n   3.25401068e-01 -7.09568411e-02 -3.40349823e-01  3.53175700e-01\\n  -1.40870750e-01  1.48104727e-01  1.29613146e-01 -4.31074165e-02\\n  -4.88656640e-01  3.30274105e-01 -2.47303024e-01 -1.50330618e-01\\n   6.16473407e-02 -5.14049411e-01 -7.20997751e-02  1.15514778e-01\\n   4.62278947e-02 -5.60116917e-02 -1.69485658e-02 -9.68427435e-02\\n   1.74150988e-01  2.25662053e-01 -1.62889552e+00  6.65452600e-01\\n   3.67325634e-01 -1.63979799e-01  1.50619775e-01  1.51648641e-01\\n  -5.82171202e-01  5.99627256e-01 -1.82380006e-01  2.27947384e-01\\n  -4.85972047e-01 -2.07147807e-01  3.60150822e-02  3.75039965e-01\\n  -7.54834190e-02 -2.10521728e-01  2.17336714e-01 -3.61611813e-01\\n  -7.23754093e-02 -1.96381047e-01 -3.38285327e-01  3.00822526e-01\\n   2.96807528e-01 -3.60810429e-01 -1.93178490e-01  4.68526632e-02\\n  -1.28632952e-02  5.93999922e-01 -1.52150616e-01  1.45273313e-01\\n   3.53429168e-01 -1.99988529e-01 -2.85502374e-01 -9.94238108e-02\\n   5.22941291e-01  4.71777976e-01 -4.64437753e-02 -3.20489824e-01\\n   2.70593554e-01  9.49235559e-02  3.63075063e-02  5.05855143e-01\\n   4.53346252e-01 -4.38093066e-01  3.76168609e-01  2.64296889e-01\\n  -1.99462101e-02  2.08283141e-01  2.65816182e-01 -7.34181225e-01\\n  -3.67749363e-01  1.38714164e-01 -1.17215058e-02 -1.97501272e-01\\n  -1.42075360e-01 -1.40151069e-01 -3.25636864e-01 -1.47167414e-01\\n  -1.91212162e-01  1.62024796e-02 -1.04415737e-01 -2.69607872e-01\\n  -2.57188201e-01 -5.47270849e-02 -3.18497747e-01 -6.03393853e-01\\n  -1.42443866e-01 -3.98455679e-01 -3.61690879e-01  7.53029957e-02\\n   3.10212582e-01 -8.36690962e-02 -2.21209943e-01  9.98403430e-02\\n  -1.24768317e-01  2.77627587e-01 -4.17370349e-02  7.19733775e-01\\n   3.63692418e-02 -3.31575841e-01  1.78003728e-01 -6.92021966e-01\\n  -2.72590697e-01  3.76816779e-01 -2.62202412e-01  4.22311962e-01\\n  -2.37872675e-01  2.19237119e-01 -1.54483229e-01 -4.75793868e-01\\n  -6.13492370e-01 -3.23269427e-01  7.02557921e-01  1.54788464e-01\\n   1.32734016e-01  4.36126851e-02 -1.25753820e-01  7.73143023e-03\\n  -1.62248582e-01  2.04351336e-01 -4.06269163e-01  8.49670991e-02\\n   3.98866147e-01  4.57837671e-01  9.79636982e-03  5.67638159e-01\\n   6.00887358e-01  1.32411823e-01 -4.35220897e-01 -1.25125885e-01\\n   1.23945937e-01  9.60666686e-04 -1.03529610e-01 -3.99199188e-01\\n  -2.78918017e-02  2.95339644e-01  3.42015475e-01 -3.93427372e-01\\n   2.05590248e+00  5.01470566e-01  4.93452817e-01 -1.19217560e-01\\n   5.71801484e-01 -2.23250613e-01 -3.35480869e-01 -1.18381813e-01\\n  -3.10031176e-01  5.11620939e-01  1.58387274e-01  4.75364089e-01\\n  -2.94520795e-01  7.69595578e-02  4.33281302e-01  2.97105193e-01\\n  -3.21841240e-02 -3.98379654e-01 -4.08969283e-01  3.54098618e-01\\n  -3.31856906e-01 -1.12272091e-02  8.41189772e-02 -4.47090305e-02\\n   3.69698942e-01  2.47243345e-02  9.91751999e-02 -1.21616647e-02\\n  -5.96484318e-02  3.58257964e-02 -1.63500085e-01 -1.40766084e-01\\n   3.07768703e-01  5.10451257e-01 -3.44443321e-01 -4.70936447e-02\\n   2.85872277e-02  3.08962017e-02 -3.23935986e-01  2.06725687e-01\\n   5.11202998e-02 -1.91376433e-01  5.52959740e-01 -4.18608412e-02\\n  -1.58205591e-02  3.98203164e-01 -2.39138186e-01 -1.01740152e-01\\n   5.64973354e-01  2.97782540e-01  5.37085012e-02 -5.62624753e-01\\n  -2.41828114e-01  9.68055502e-02 -2.66226649e-01 -1.79441795e-01\\n  -2.81063050e-01 -9.50718373e-02  1.94720358e-01  2.89402992e-01\\n  -1.54137090e-01  9.73331258e-02 -4.66218404e-03 -1.91271171e-01\\n  -2.07760990e-01 -3.11409146e-01 -5.08566499e-01  5.24864309e-02\\n   4.12123591e-01 -5.80670953e-01 -2.59671211e-02  1.99985608e-01\\n   4.23747897e-02 -1.63506493e-02  5.22389352e-01 -3.03644966e-02\\n   2.09079921e-01 -2.55354941e-01 -3.08615863e-01 -2.90557265e+00\\n   1.55386716e-01  3.39695103e-02 -1.84234488e-03  5.26570454e-02\\n   3.89243096e-01  9.01866928e-02  6.10042587e-02  3.31049412e-01\\n  -2.57059753e-01 -6.35109991e-02  5.18513739e-01  1.79683387e-01\\n   1.15560696e-01  9.23437551e-02  1.36667028e-01  3.60141918e-02\\n  -1.13908902e-01 -3.12253777e-02 -2.83547640e-02  3.19167599e-02\\n  -2.14082301e-02 -4.81753826e-01 -3.16776454e-01  1.46693692e-01\\n   6.23413861e-01 -6.42890483e-03 -1.01053163e-01  5.14142931e-01\\n   2.79165208e-02 -9.56750363e-02  3.26557219e-01 -1.04178466e-01\\n   1.72649294e-01  8.15937221e-02  5.50018996e-03 -6.18965685e-01\\n   1.54309228e-01 -3.86686087e-01 -1.87500685e-01  3.95972980e-03\\n   5.63342214e-01 -1.06397629e-01 -1.58954799e-01  1.08260378e-01\\n  -1.80927455e-01  3.26693594e-01 -5.70347831e-02  6.25436962e-01\\n  -9.23378766e-02  2.89802015e-01 -2.63040513e-01 -5.64963110e-02\\n  -1.66508704e-01  2.54119188e-01  4.98597920e-02 -1.32797062e-02\\n  -6.77917078e-02 -1.27877608e-01 -5.16939402e-01 -3.43055353e-02\\n   9.74645391e-02 -1.32807642e-01  9.30911675e-02  1.44518673e-01\\n  -1.90143377e-01 -6.39199317e-02 -2.02922881e-01 -1.39917299e-01\\n   2.47079968e-01 -3.52009773e-01  9.93810743e-02  2.89841890e-01\\n  -1.30606756e-01  3.48945677e-01  2.88481824e-02  3.50199252e-01\\n   4.24805731e-02 -1.59582525e-01  4.88326699e-02  3.06095481e-02\\n   9.38794464e-02 -2.19642878e-01  3.37566882e-01 -3.15695219e-02\\n  -7.41860151e+00 -7.85215721e-02 -3.51866245e-01 -2.27984726e-01\\n  -1.91109449e-01 -5.63996553e-01  9.82976258e-02  1.16897427e-01\\n  -5.29898703e-02 -9.74458158e-02  2.64452159e-01 -1.89303577e-01\\n  -2.68083125e-01 -5.93935668e-01  7.06842065e-01 -2.05847528e-03]]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Anger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.327919228349294,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Anxiety\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2871627031849655,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Curiosity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32791922834929477,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Desire\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22314554728547412,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Happiness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32791922834929443,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Love & Care\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3279192283492944,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3470456402286526,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Relief\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3052272392470903,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion_Sadness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3279192283492945,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_experiment = data.iloc[:, :-9].values  # First 768 columns are BERT embeddings\n",
        "Y_experiment = data.iloc[:, -9:].values  # Last 10 columns are emotion labels\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_experiment, X_test_experiment, Y_train_experiment, Y_test_experiment = train_test_split(X_experiment, Y_experiment, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "7Nt_TqfiDCNY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have X_train, X_test, y_train, y_test\n",
        "X_train_experiment = X_train_experiment.reshape(X_train_experiment.shape[0], X_train_experiment.shape[1], 1)  # (45696, 768, 1)\n",
        "X_test_experiment = X_test_experiment.reshape(X_test_experiment.shape[0], X_test_experiment.shape[1], 1)      # (11425, 768, 1)\n",
        "\n",
        "print(\"New Shapes:\")\n",
        "print(\"X_train:\", X_train_experiment.shape)  # (45696, 768, 1)\n",
        "print(\"y_train:\", Y_train_experiment.shape)  # (45696, 9)\n",
        "print(\"X_test:\", X_test_experiment.shape)    # (11425, 768, 1)\n",
        "print(\"y_test:\", Y_test_experiment.shape)    # (11425, 9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TV6J8VkDgf0",
        "outputId": "90db3dac-246f-4961-f8dc-837205e998b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Shapes:\n",
            "X_train: (45696, 768, 1)\n",
            "y_train: (45696, 9)\n",
            "X_test: (11425, 768, 1)\n",
            "y_test: (11425, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have X_train, X_test, y_train, y_test\n",
        "X_train_experiment = X_train_experiment.reshape(X_train_experiment.shape[0], X_train_experiment.shape[1], 1)  # (45696, 768, 1)\n",
        "X_test_experiment = X_test_experiment.reshape(X_test_experiment.shape[0], X_test_experiment.shape[1], 1)      # (11425, 768, 1)\n",
        "\n",
        "print(\"New Shapes:\")\n",
        "print(\"X_train:\", X_train_experiment.shape)  # (45696, 768, 1)\n",
        "print(\"y_train:\", Y_train_experiment.shape)  # (45696, 9)\n",
        "print(\"X_test:\", X_test_experiment.shape)    # (11425, 768, 1)\n",
        "print(\"y_test:\", Y_test_experiment.shape)    # (11425, 9)\n"
      ],
      "metadata": {
        "id": "xdDF-gawDouD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM, Input\n",
        "\n"
      ],
      "metadata": {
        "id": "0aZPeylnMLy5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(X_train_experiment.shape[1], 1)),  # Input shape (num_features, 1) for LSTM\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),  # First BiLSTM layer\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(64)),  # Second BiLSTM layer\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),  # Fully connected layer\n",
        "    Dropout(0.3),\n",
        "    Dense(Y_train_experiment.shape[1], activation='softmax')  # Output layer (multi-class classification)\n",
        "])"
      ],
      "metadata": {
        "id": "Y2U5XIjIML11"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "U4w5_Pw9ML5B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_bilstm_model.h5', monitor='val_loss', save_best_only=True)\n"
      ],
      "metadata": {
        "id": "Vl4MEwpSML8m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "qmfrnvQnMaDB",
        "outputId": "2f115606-6693-4f5f-8a52-f1d1b5a0618a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m133,120\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m164,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │             \u001b[38;5;34m585\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">133,120</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m306,313\u001b[0m (1.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306,313</span> (1.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m306,313\u001b[0m (1.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306,313</span> (1.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_experiment.reshape(-1, X_train_experiment.shape[1], 1), Y_train_experiment,\n",
        "    validation_data=(X_test_experiment.reshape(-1, X_test_experiment.shape[1], 1), Y_test_experiment),\n",
        "    epochs=30, batch_size=32,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HASIGwJaMcjZ",
        "outputId": "0bcf53f0-34e0-41e5-ab15-6de4aad98d33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1350 - loss: 2.1742"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 106ms/step - accuracy: 0.1350 - loss: 2.1742 - val_accuracy: 0.1599 - val_loss: 2.1515\n",
            "Epoch 2/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1646 - loss: 2.1520"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 109ms/step - accuracy: 0.1646 - loss: 2.1520 - val_accuracy: 0.1675 - val_loss: 2.1396\n",
            "Epoch 3/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1757 - loss: 2.1367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 105ms/step - accuracy: 0.1757 - loss: 2.1367 - val_accuracy: 0.1898 - val_loss: 2.1178\n",
            "Epoch 4/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1824 - loss: 2.1303"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 110ms/step - accuracy: 0.1824 - loss: 2.1303 - val_accuracy: 0.1980 - val_loss: 2.1048\n",
            "Epoch 5/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1898 - loss: 2.1163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 105ms/step - accuracy: 0.1898 - loss: 2.1163 - val_accuracy: 0.2058 - val_loss: 2.0832\n",
            "Epoch 6/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2005 - loss: 2.0988"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 105ms/step - accuracy: 0.2005 - loss: 2.0988 - val_accuracy: 0.2083 - val_loss: 2.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.2021 - loss: 2.0911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 110ms/step - accuracy: 0.2021 - loss: 2.0911 - val_accuracy: 0.2105 - val_loss: 2.0750\n",
            "Epoch 8/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2118 - loss: 2.0764"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 110ms/step - accuracy: 0.2118 - loss: 2.0764 - val_accuracy: 0.2179 - val_loss: 2.0692\n",
            "Epoch 9/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 105ms/step - accuracy: 0.2118 - loss: 2.0760 - val_accuracy: 0.2141 - val_loss: 2.0707\n",
            "Epoch 10/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2144 - loss: 2.0687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 110ms/step - accuracy: 0.2144 - loss: 2.0687 - val_accuracy: 0.2235 - val_loss: 2.0557\n",
            "Epoch 11/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 109ms/step - accuracy: 0.2222 - loss: 2.0587 - val_accuracy: 0.2214 - val_loss: 2.0610\n",
            "Epoch 12/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2251 - loss: 2.0528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 109ms/step - accuracy: 0.2251 - loss: 2.0528 - val_accuracy: 0.2264 - val_loss: 2.0419\n",
            "Epoch 13/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2329 - loss: 2.0399"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 109ms/step - accuracy: 0.2329 - loss: 2.0399 - val_accuracy: 0.2330 - val_loss: 2.0354\n",
            "Epoch 14/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2354 - loss: 2.0347"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 105ms/step - accuracy: 0.2354 - loss: 2.0347 - val_accuracy: 0.2333 - val_loss: 2.0306\n",
            "Epoch 15/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2371 - loss: 2.0210"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 109ms/step - accuracy: 0.2371 - loss: 2.0210 - val_accuracy: 0.2371 - val_loss: 2.0254\n",
            "Epoch 16/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2455 - loss: 2.0177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 109ms/step - accuracy: 0.2455 - loss: 2.0177 - val_accuracy: 0.2432 - val_loss: 2.0159\n",
            "Epoch 17/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 110ms/step - accuracy: 0.2450 - loss: 2.0123 - val_accuracy: 0.2411 - val_loss: 2.0215\n",
            "Epoch 18/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 109ms/step - accuracy: 0.2482 - loss: 2.0065 - val_accuracy: 0.2353 - val_loss: 2.0225\n",
            "Epoch 19/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.2508 - loss: 1.9965"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 110ms/step - accuracy: 0.2508 - loss: 1.9965 - val_accuracy: 0.2439 - val_loss: 2.0130\n",
            "Epoch 20/30\n",
            "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.2542 - loss: 1.9935"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 109ms/step - accuracy: 0.2542 - loss: 1.9935 - val_accuracy: 0.2456 - val_loss: 2.0129\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-37d36cf00d07>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_train_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_experiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_experiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}